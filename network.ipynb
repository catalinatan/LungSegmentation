{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'base (Python 3.12.2)' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'conda install -n base ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from pathlib import Path\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import CenterCrop\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by:<br>\n",
    "https://pyimagesearch.com/2021/11/08/u-net-training-image-segmentation-models-in-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, inChannels, outChannels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(inChannels, outChannels, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(outChannels, outChannels, kernel_size=3)\n",
    "    def forward(self, x):\n",
    "        return self.conv2(F.relu(self.conv1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    # Input: (1,1,256,256)\n",
    "    # Block1 → (1,64,256,256) → Pool → (1,64,128,128)\n",
    "    # Block2 → (1,128,128,128) → Pool → (1,128,64,64)\n",
    "    # Block3 → (1,256,64,64) → Pool → (1,256,32,32)\n",
    "    # Block4 → (1,512,32,32) → Pool → (1,512,16,16)\n",
    "    def __init__(self, channels=(1, 64, 128, 256, 512, 1024)):\n",
    "        super().__init__()\n",
    "        self.encBlocks = nn.ModuleList(\n",
    "            [Block(channels[i], channels[i + 1])\n",
    "             for i in range(len(channels) - 1)])\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "    def forward(self, x):\n",
    "        features = []\n",
    "        for block in self.encBlocks:\n",
    "            x = block(x)\n",
    "            features.append(x)\n",
    "            x = self.pool(x)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    # Upconv1: (1,512,16,16) → (1,256,32,32)\n",
    "    # Concat → (1,512,32,32) → Block → (1,256,32,32)\n",
    "    # Upconv2: → (1,128,64,64)\n",
    "    # Concat → (1,256,64,64) → Block → (1,128,64,64)\n",
    "    # Upconv3: → (1,64,128,128)\n",
    "    # Concat → (1,128,128,128) → Block → (1,64,128,128)\n",
    "    # Upconv4: → (1,32,256,256)\n",
    "    # Final Conv: → (1,2,256,256)\n",
    "    def __init__(self, channels=(1024, 512, 256, 128, 64)):\n",
    "        super().__init__()\n",
    "        self.upconvs = nn.ModuleList([\n",
    "            nn.ConvTranspose2d(channels[i], channels[i+1], kernel_size=2, stride=2)\n",
    "            for i in range(len(channels) - 1)\n",
    "        ])\n",
    "        self.dec_blocks = nn.ModuleList([\n",
    "            Block(2 * channels[i+1], channels[i+1])  # Corrected line\n",
    "            for i in range(len(channels) - 1)\n",
    "        ])\n",
    "        self.channels = channels\n",
    "    def forward(self, x, encFeatures):\n",
    "        for i in range(len(self.channels) - 1):\n",
    "            # Upsampling\n",
    "            x = self.upconvs[i](x)\n",
    "            # Cropping\n",
    "            encFeat = self.crop(encFeatures[i], x)\n",
    "            # Concatenating encoder and decoder channels (along the\n",
    "            # 1st dimension)\n",
    "            x = torch.cat([x, encFeat], dim=1)\n",
    "            x = self.dec_blocks[i](x)\n",
    "        return x\n",
    "    def crop(self, encFeatures, x):\n",
    "        (_, _, H, W) = x.shape\n",
    "        encFeatures = CenterCrop([H, W])(encFeatures)\n",
    "        return encFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, inChannels=1, outChannels=2):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "        self.finalConv = nn.Conv2d(64, outChannels, kernel_size=1)\n",
    "    def forward(self, x):\n",
    "        encFeatures = self.encoder(x)\n",
    "        x = encFeatures[-1]\n",
    "        # Reverse the order of the encoder features to match the decoder\n",
    "        x = self.decoder(x, encFeatures[-2::-1])\n",
    "        return self.finalConv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired by:<br>\n",
    "https://www.geeksforgeeks.org/converting-an-image-to-a-torch-tensor-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, size=(256, 256)):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(size),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "    return transform(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_folder, mask_folder, transform=None):\n",
    "        self.image_folder = image_folder\n",
    "        self.mask_folder = mask_folder\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(list(self.image_folder.iterdir()))\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = list(self.image_folder.iterdir())[idx]\n",
    "        mask_name = image_path.name.replace(\".png\", \"_mask.png\")\n",
    "        mask_path = self.mask_folder / mask_name\n",
    "        image = Image.open(image_path)\n",
    "        mask = Image.open(mask_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The design of the train and test network functions were written similarly to my 3rd year research project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(net, train_loader, criterion, optimizer):\n",
    "    for epoch in range(2):  # Use full 32 epochs\n",
    "        net.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "            optimizer.zero_grad()\n",
    "            labels = labels.squeeze(1).long()  # Remove channel dimension\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            # Interpolate outputs to match labels size\n",
    "            if outputs.shape[-2:] != labels.shape[-2:]:\n",
    "                outputs = F.interpolate(outputs, labels.shape[-2:], mode='bilinear')\n",
    "\n",
    "            # Calculate loss (outputs: [N, 2, H, W], labels: [N, H, W])\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1} Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_network(net, test_loader):\n",
    "    net.eval()\n",
    "    true_positives, true_negatives, false_positives, false_negatives = 0, 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "            # Forward pass\n",
    "           \n",
    "            labels = labels.squeeze(1).long()  # Remove channel dimension\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            # Interpolate outputs to match labels size\n",
    "            if outputs.shape[-2:] != labels.shape[-2:]:\n",
    "                outputs = F.interpolate(outputs, labels.shape[-2:], mode='bilinear')\n",
    "            print(f\"Labels shape: {labels.shape}\")\n",
    "            __, predicted = torch.max(outputs.data, 1)\n",
    "            matches = (predicted == labels)\n",
    "            correct = matches.sum().item()\n",
    "            total = len(labels)\n",
    "            true_positives += ((predicted == 1) & (labels == 1)).sum().item()\n",
    "            true_negatives += ((predicted == 0) & (labels == 0)).sum().item()\n",
    "            false_positives += ((predicted == 1) & (labels == 0)).sum().item()\n",
    "            false_negatives += ((predicted == 0) & (labels == 1)).sum().item()\n",
    "        precision = (\n",
    "            true_positives / (true_positives + false_positives)\n",
    "            if true_positives + false_positives > 0\n",
    "            else 0\n",
    "        )\n",
    "        sensitivity = (\n",
    "            true_positives / (true_positives + false_negatives)\n",
    "            if true_positives + false_negatives > 0\n",
    "            else 0\n",
    "        )\n",
    "        specificity = (\n",
    "            true_negatives / (true_negatives + false_positives)\n",
    "            if true_negatives + false_positives > 0\n",
    "            else 0\n",
    "        )\n",
    "        print(f\"true_positives: {true_positives}\")\n",
    "        print(f\"true_negatives: {true_negatives}\")\n",
    "        print(f\"false_positives: {false_positives}\")\n",
    "        print(f\"false_negatives: {false_negatives}\")\n",
    "        print(f\"Accuracy: {correct / total:.2f}\")\n",
    "        print(\"Confusion Matrix\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Sensitivity: {sensitivity:.4f}\")\n",
    "        print(f\"Specificity: {specificity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_folder = Path(\"data/train\")\n",
    "    train_image_folder = train_folder / \"images\"\n",
    "    train_mask_folder = train_folder / \"masks\"\n",
    "    val_folder = Path(\"data/val\")\n",
    "    val_image_folder = val_folder / \"images\"\n",
    "    test_mask_folder = val_folder / \"masks\"\n",
    "\n",
    "    # Create dataset instance\n",
    "    train_dataset = ImageDataset(train_image_folder, train_mask_folder, transform=resize_image)\n",
    "    val_dataset = ImageDataset(val_image_folder, test_mask_folder, transform=resize_image)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "    test_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    # Define the network\n",
    "    net = UNet()\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001)  # Use Adam optimizer\n",
    "\n",
    "    # Train the network\n",
    "    train_network(net, train_loader, criterion, optimizer)\n",
    "    # Test the network\n",
    "    test_network(net, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
